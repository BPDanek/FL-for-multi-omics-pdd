{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# linear_non_strat_path = '/Users/benjamindanek/Downloads/last_runs/manual_experiments_linear_non_strat'\n",
    "# uniform_non_strat_path = '/Users/benjamindanek/Downloads/last_runs/manual_experiments_uniform_non_strat'\n",
    "# uniform_strat_path = '/Users/benjamindanek/Downloads/last_runs/manual_experiments_uniform_strat'\n",
    "\n",
    "tables_path = '/Users/benjamindanek/Code/federated_learning_multi_modality_ancestry/multi_modality_fl/results/generated_figures_tables'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"PPMI\"\n",
    "NC = 2\n",
    "metric = \"auc_precision_recall\"\n",
    "\n",
    "us_table = (f'k_averaged_results_table_k_all {dataset} Uniform Stratified test.csv', True)\n",
    "ur_table = (f'k_averaged_results_table_k_all {dataset} Uniform Random test.csv', False)\n",
    "lr_table = (f'k_averaged_results_table_k_all {dataset} Linear Random test.csv', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['algorithm_name', 'num_clients', 'split_method', 'val_name', 'fold_idx',\n",
       "       'roc_auc_score', 'auc_precision_recall', 'accuracy_score',\n",
       "       'precision_score', 'recall_score', 'average_precision_score',\n",
       "       'fbeta_score_0.5', 'fbeta_score_1', 'fbeta_score_2', 'log_loss',\n",
       "       'matthews_corrcoef', 'algorithm_name_std', 'num_clients_std',\n",
       "       'split_method_std', 'val_name_std', 'fold_idx_std', 'roc_auc_score_std',\n",
       "       'auc_precision_recall_std', 'accuracy_score_std', 'precision_score_std',\n",
       "       'recall_score_std', 'average_precision_score_std',\n",
       "       'fbeta_score_0.5_std', 'fbeta_score_1_std', 'fbeta_score_2_std',\n",
       "       'log_loss_std', 'matthews_corrcoef_std'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['algorithm_name', 'num_clients', 'split_method', 'val_name', 'fold_idx',\n",
       "       'roc_auc_score', 'auc_precision_recall', 'accuracy_score',\n",
       "       'precision_score', 'recall_score', 'average_precision_score',\n",
       "       'fbeta_score_0.5', 'fbeta_score_1', 'fbeta_score_2', 'log_loss',\n",
       "       'matthews_corrcoef', 'algorithm_name_std', 'num_clients_std',\n",
       "       'split_method_std', 'val_name_std', 'fold_idx_std', 'roc_auc_score_std',\n",
       "       'auc_precision_recall_std', 'accuracy_score_std', 'precision_score_std',\n",
       "       'recall_score_std', 'average_precision_score_std',\n",
       "       'fbeta_score_0.5_std', 'fbeta_score_1_std', 'fbeta_score_2_std',\n",
       "       'log_loss_std', 'matthews_corrcoef_std'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['algorithm_name', 'num_clients', 'split_method', 'val_name', 'fold_idx',\n",
       "       'roc_auc_score', 'auc_precision_recall', 'accuracy_score',\n",
       "       'precision_score', 'recall_score', 'average_precision_score',\n",
       "       'fbeta_score_0.5', 'fbeta_score_1', 'fbeta_score_2', 'log_loss',\n",
       "       'matthews_corrcoef', 'algorithm_name_std', 'num_clients_std',\n",
       "       'split_method_std', 'val_name_std', 'fold_idx_std', 'roc_auc_score_std',\n",
       "       'auc_precision_recall_std', 'accuracy_score_std', 'precision_score_std',\n",
       "       'recall_score_std', 'average_precision_score_std',\n",
       "       'fbeta_score_0.5_std', 'fbeta_score_1_std', 'fbeta_score_2_std',\n",
       "       'log_loss_std', 'matthews_corrcoef_std'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tables = []\n",
    "for table_file_name, stratified in [us_table, ur_table, lr_table]: \n",
    "    table = pd.read_csv(os.path.join(tables_path, table_file_name))\n",
    "    table = pd.concat([table[table['num_clients'] == 2], table[table['num_clients'] == 4]])\n",
    "    display(table.columns)\n",
    "    table['algorithm_name'] = table['algorithm_name'].apply(lambda x: x.replace('Classifier', '') if type(x) == str else x).apply(lambda x: x.replace('FedProx μ = 0', 'FedProx μ = 0.5'))\n",
    "    # table = table.round(4)\n",
    "    # table[f\"str_{metric}\"] = table[metric].astype(str) + ' ± ' + table[f\"{metric}_std\"].astype(str)\n",
    "\n",
    "    table['stratified'] = stratified\n",
    "    tables.append(table)\n",
    "\n",
    "tables = pd.concat(tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm_name</th>\n",
       "      <th>num_clients</th>\n",
       "      <th>split_method</th>\n",
       "      <th>val_name</th>\n",
       "      <th>fold_idx</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>auc_precision_recall</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>...</th>\n",
       "      <th>accuracy_score_std</th>\n",
       "      <th>precision_score_std</th>\n",
       "      <th>recall_score_std</th>\n",
       "      <th>average_precision_score_std</th>\n",
       "      <th>fbeta_score_0.5_std</th>\n",
       "      <th>fbeta_score_1_std</th>\n",
       "      <th>fbeta_score_2_std</th>\n",
       "      <th>log_loss_std</th>\n",
       "      <th>matthews_corrcoef_std</th>\n",
       "      <th>stratified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FedAvg LR</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.689773</td>\n",
       "      <td>0.873723</td>\n",
       "      <td>0.617201</td>\n",
       "      <td>0.533132</td>\n",
       "      <td>0.622066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261588</td>\n",
       "      <td>0.414227</td>\n",
       "      <td>0.482046</td>\n",
       "      <td>0.094197</td>\n",
       "      <td>0.425912</td>\n",
       "      <td>0.445021</td>\n",
       "      <td>0.466358</td>\n",
       "      <td>0.139675</td>\n",
       "      <td>0.249825</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FedAvg MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.760004</td>\n",
       "      <td>0.872462</td>\n",
       "      <td>0.712220</td>\n",
       "      <td>0.816843</td>\n",
       "      <td>0.767606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083873</td>\n",
       "      <td>0.051478</td>\n",
       "      <td>0.088520</td>\n",
       "      <td>0.068716</td>\n",
       "      <td>0.055323</td>\n",
       "      <td>0.065779</td>\n",
       "      <td>0.079040</td>\n",
       "      <td>0.308273</td>\n",
       "      <td>0.179210</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FedAvg SGD</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.828008</td>\n",
       "      <td>0.919800</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.904037</td>\n",
       "      <td>0.706573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029390</td>\n",
       "      <td>0.048977</td>\n",
       "      <td>0.032628</td>\n",
       "      <td>0.024662</td>\n",
       "      <td>0.032386</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>0.026878</td>\n",
       "      <td>0.032096</td>\n",
       "      <td>0.083677</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FedAvg XGBRF</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.828651</td>\n",
       "      <td>0.924113</td>\n",
       "      <td>0.800505</td>\n",
       "      <td>0.847752</td>\n",
       "      <td>0.882629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.042688</td>\n",
       "      <td>0.036366</td>\n",
       "      <td>0.018673</td>\n",
       "      <td>0.028679</td>\n",
       "      <td>0.013386</td>\n",
       "      <td>0.023111</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.088943</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FedProx μ = 0.5 LR</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.754560</td>\n",
       "      <td>0.887329</td>\n",
       "      <td>0.704595</td>\n",
       "      <td>0.671177</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208265</td>\n",
       "      <td>0.329532</td>\n",
       "      <td>0.379707</td>\n",
       "      <td>0.081846</td>\n",
       "      <td>0.338324</td>\n",
       "      <td>0.352573</td>\n",
       "      <td>0.368288</td>\n",
       "      <td>0.154714</td>\n",
       "      <td>0.198308</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>FedProx μ = 0.5 MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.756737</td>\n",
       "      <td>0.871983</td>\n",
       "      <td>0.743712</td>\n",
       "      <td>0.829433</td>\n",
       "      <td>0.807512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074669</td>\n",
       "      <td>0.047859</td>\n",
       "      <td>0.075410</td>\n",
       "      <td>0.059007</td>\n",
       "      <td>0.048029</td>\n",
       "      <td>0.054443</td>\n",
       "      <td>0.066003</td>\n",
       "      <td>0.313834</td>\n",
       "      <td>0.181533</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>FedProx μ = 2 LR</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.812445</td>\n",
       "      <td>0.906127</td>\n",
       "      <td>0.777332</td>\n",
       "      <td>0.790153</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023524</td>\n",
       "      <td>0.014448</td>\n",
       "      <td>0.024798</td>\n",
       "      <td>0.039429</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.016530</td>\n",
       "      <td>0.020675</td>\n",
       "      <td>0.137376</td>\n",
       "      <td>0.068946</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>FedProx μ = 2 MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.764644</td>\n",
       "      <td>0.868148</td>\n",
       "      <td>0.738562</td>\n",
       "      <td>0.830074</td>\n",
       "      <td>0.798122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053685</td>\n",
       "      <td>0.042344</td>\n",
       "      <td>0.045129</td>\n",
       "      <td>0.057369</td>\n",
       "      <td>0.038986</td>\n",
       "      <td>0.037932</td>\n",
       "      <td>0.041217</td>\n",
       "      <td>0.367971</td>\n",
       "      <td>0.133159</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FedAvg LR</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.730323</td>\n",
       "      <td>0.876311</td>\n",
       "      <td>0.679739</td>\n",
       "      <td>0.629342</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195043</td>\n",
       "      <td>0.308643</td>\n",
       "      <td>0.400456</td>\n",
       "      <td>0.077422</td>\n",
       "      <td>0.323346</td>\n",
       "      <td>0.348354</td>\n",
       "      <td>0.377765</td>\n",
       "      <td>0.110126</td>\n",
       "      <td>0.147557</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FedAvg MLP</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.772909</td>\n",
       "      <td>0.876451</td>\n",
       "      <td>0.747128</td>\n",
       "      <td>0.836818</td>\n",
       "      <td>0.805164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064906</td>\n",
       "      <td>0.054659</td>\n",
       "      <td>0.058695</td>\n",
       "      <td>0.066108</td>\n",
       "      <td>0.047701</td>\n",
       "      <td>0.045198</td>\n",
       "      <td>0.051454</td>\n",
       "      <td>0.261040</td>\n",
       "      <td>0.170983</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FedAvg SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.794320</td>\n",
       "      <td>0.897981</td>\n",
       "      <td>0.688305</td>\n",
       "      <td>0.882143</td>\n",
       "      <td>0.652582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047382</td>\n",
       "      <td>0.058454</td>\n",
       "      <td>0.032931</td>\n",
       "      <td>0.042840</td>\n",
       "      <td>0.045213</td>\n",
       "      <td>0.034710</td>\n",
       "      <td>0.032208</td>\n",
       "      <td>0.058866</td>\n",
       "      <td>0.120626</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FedAvg XGBRF</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.800313</td>\n",
       "      <td>0.901946</td>\n",
       "      <td>0.767380</td>\n",
       "      <td>0.824452</td>\n",
       "      <td>0.859155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054478</td>\n",
       "      <td>0.050176</td>\n",
       "      <td>0.035631</td>\n",
       "      <td>0.055826</td>\n",
       "      <td>0.043288</td>\n",
       "      <td>0.035383</td>\n",
       "      <td>0.033022</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.153223</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>FedProx μ = 0.5 LR</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.885298</td>\n",
       "      <td>0.683106</td>\n",
       "      <td>0.633008</td>\n",
       "      <td>0.814554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197443</td>\n",
       "      <td>0.310578</td>\n",
       "      <td>0.399505</td>\n",
       "      <td>0.080489</td>\n",
       "      <td>0.324926</td>\n",
       "      <td>0.349234</td>\n",
       "      <td>0.377673</td>\n",
       "      <td>0.119413</td>\n",
       "      <td>0.164419</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FedProx μ = 0.5 MLP</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.773893</td>\n",
       "      <td>0.876254</td>\n",
       "      <td>0.750297</td>\n",
       "      <td>0.837511</td>\n",
       "      <td>0.805164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088255</td>\n",
       "      <td>0.050764</td>\n",
       "      <td>0.082327</td>\n",
       "      <td>0.060135</td>\n",
       "      <td>0.055450</td>\n",
       "      <td>0.064441</td>\n",
       "      <td>0.074882</td>\n",
       "      <td>0.248645</td>\n",
       "      <td>0.204304</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>FedProx μ = 2 LR</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.732059</td>\n",
       "      <td>0.878554</td>\n",
       "      <td>0.684740</td>\n",
       "      <td>0.639297</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198510</td>\n",
       "      <td>0.313732</td>\n",
       "      <td>0.393964</td>\n",
       "      <td>0.078936</td>\n",
       "      <td>0.326886</td>\n",
       "      <td>0.348984</td>\n",
       "      <td>0.374546</td>\n",
       "      <td>0.107227</td>\n",
       "      <td>0.170084</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>FedProx μ = 2 MLP</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.753508</td>\n",
       "      <td>0.866042</td>\n",
       "      <td>0.740394</td>\n",
       "      <td>0.831352</td>\n",
       "      <td>0.798122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068732</td>\n",
       "      <td>0.047940</td>\n",
       "      <td>0.053940</td>\n",
       "      <td>0.068713</td>\n",
       "      <td>0.047947</td>\n",
       "      <td>0.049266</td>\n",
       "      <td>0.051786</td>\n",
       "      <td>0.253359</td>\n",
       "      <td>0.164822</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FedAvg LR</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.727821</td>\n",
       "      <td>0.876881</td>\n",
       "      <td>0.696376</td>\n",
       "      <td>0.660803</td>\n",
       "      <td>0.779343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203317</td>\n",
       "      <td>0.324156</td>\n",
       "      <td>0.382898</td>\n",
       "      <td>0.072955</td>\n",
       "      <td>0.334020</td>\n",
       "      <td>0.350372</td>\n",
       "      <td>0.368974</td>\n",
       "      <td>0.130071</td>\n",
       "      <td>0.177841</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FedAvg MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.767768</td>\n",
       "      <td>0.877249</td>\n",
       "      <td>0.740295</td>\n",
       "      <td>0.827109</td>\n",
       "      <td>0.805164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068286</td>\n",
       "      <td>0.050626</td>\n",
       "      <td>0.049929</td>\n",
       "      <td>0.062655</td>\n",
       "      <td>0.048739</td>\n",
       "      <td>0.047565</td>\n",
       "      <td>0.048376</td>\n",
       "      <td>0.228905</td>\n",
       "      <td>0.172388</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FedAvg SGD</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.816022</td>\n",
       "      <td>0.907412</td>\n",
       "      <td>0.703506</td>\n",
       "      <td>0.882674</td>\n",
       "      <td>0.678404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046347</td>\n",
       "      <td>0.065495</td>\n",
       "      <td>0.048313</td>\n",
       "      <td>0.048111</td>\n",
       "      <td>0.045812</td>\n",
       "      <td>0.036258</td>\n",
       "      <td>0.042201</td>\n",
       "      <td>0.071575</td>\n",
       "      <td>0.122341</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FedAvg XGBRF</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.785955</td>\n",
       "      <td>0.904351</td>\n",
       "      <td>0.751783</td>\n",
       "      <td>0.839760</td>\n",
       "      <td>0.812207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033173</td>\n",
       "      <td>0.048316</td>\n",
       "      <td>0.053940</td>\n",
       "      <td>0.043312</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>0.022274</td>\n",
       "      <td>0.038089</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.109365</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FedProx μ = 0.5 LR</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.692778</td>\n",
       "      <td>0.872303</td>\n",
       "      <td>0.622252</td>\n",
       "      <td>0.528627</td>\n",
       "      <td>0.638498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263720</td>\n",
       "      <td>0.409569</td>\n",
       "      <td>0.495139</td>\n",
       "      <td>0.096837</td>\n",
       "      <td>0.424166</td>\n",
       "      <td>0.448186</td>\n",
       "      <td>0.475187</td>\n",
       "      <td>0.147971</td>\n",
       "      <td>0.241376</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FedProx μ = 0.5 MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.777823</td>\n",
       "      <td>0.882572</td>\n",
       "      <td>0.738810</td>\n",
       "      <td>0.838934</td>\n",
       "      <td>0.786385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062510</td>\n",
       "      <td>0.049365</td>\n",
       "      <td>0.063250</td>\n",
       "      <td>0.063901</td>\n",
       "      <td>0.044433</td>\n",
       "      <td>0.046271</td>\n",
       "      <td>0.055405</td>\n",
       "      <td>0.298565</td>\n",
       "      <td>0.150623</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FedProx μ = 2 LR</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.637324</td>\n",
       "      <td>0.865954</td>\n",
       "      <td>0.528768</td>\n",
       "      <td>0.391762</td>\n",
       "      <td>0.467136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262370</td>\n",
       "      <td>0.429278</td>\n",
       "      <td>0.511903</td>\n",
       "      <td>0.097544</td>\n",
       "      <td>0.443571</td>\n",
       "      <td>0.466914</td>\n",
       "      <td>0.492891</td>\n",
       "      <td>0.140463</td>\n",
       "      <td>0.203402</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FedProx μ = 2 MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.747496</td>\n",
       "      <td>0.867655</td>\n",
       "      <td>0.718657</td>\n",
       "      <td>0.821718</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069853</td>\n",
       "      <td>0.047807</td>\n",
       "      <td>0.075059</td>\n",
       "      <td>0.065736</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.052884</td>\n",
       "      <td>0.065264</td>\n",
       "      <td>0.248833</td>\n",
       "      <td>0.163476</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FedAvg LR</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.676108</td>\n",
       "      <td>0.860770</td>\n",
       "      <td>0.612250</td>\n",
       "      <td>0.513581</td>\n",
       "      <td>0.652582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255731</td>\n",
       "      <td>0.398047</td>\n",
       "      <td>0.505684</td>\n",
       "      <td>0.086246</td>\n",
       "      <td>0.415656</td>\n",
       "      <td>0.445282</td>\n",
       "      <td>0.479599</td>\n",
       "      <td>0.106602</td>\n",
       "      <td>0.215334</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FedAvg MLP</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.766897</td>\n",
       "      <td>0.875666</td>\n",
       "      <td>0.726827</td>\n",
       "      <td>0.827184</td>\n",
       "      <td>0.784038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052383</td>\n",
       "      <td>0.048336</td>\n",
       "      <td>0.055391</td>\n",
       "      <td>0.064580</td>\n",
       "      <td>0.039184</td>\n",
       "      <td>0.037624</td>\n",
       "      <td>0.046877</td>\n",
       "      <td>0.284105</td>\n",
       "      <td>0.140174</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FedAvg SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.795923</td>\n",
       "      <td>0.896941</td>\n",
       "      <td>0.694890</td>\n",
       "      <td>0.895564</td>\n",
       "      <td>0.654930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035698</td>\n",
       "      <td>0.064737</td>\n",
       "      <td>0.061554</td>\n",
       "      <td>0.048059</td>\n",
       "      <td>0.036401</td>\n",
       "      <td>0.032085</td>\n",
       "      <td>0.050195</td>\n",
       "      <td>0.059499</td>\n",
       "      <td>0.105628</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FedAvg XGBRF</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.825733</td>\n",
       "      <td>0.922086</td>\n",
       "      <td>0.779065</td>\n",
       "      <td>0.802731</td>\n",
       "      <td>0.917840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061004</td>\n",
       "      <td>0.045157</td>\n",
       "      <td>0.055212</td>\n",
       "      <td>0.031522</td>\n",
       "      <td>0.041620</td>\n",
       "      <td>0.040141</td>\n",
       "      <td>0.046249</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.183375</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FedProx μ = 0.5 LR</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.621311</td>\n",
       "      <td>0.855088</td>\n",
       "      <td>0.527085</td>\n",
       "      <td>0.385972</td>\n",
       "      <td>0.476526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260635</td>\n",
       "      <td>0.422970</td>\n",
       "      <td>0.522109</td>\n",
       "      <td>0.089368</td>\n",
       "      <td>0.439663</td>\n",
       "      <td>0.467333</td>\n",
       "      <td>0.498724</td>\n",
       "      <td>0.095420</td>\n",
       "      <td>0.195162</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FedProx μ = 0.5 MLP</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.765415</td>\n",
       "      <td>0.877384</td>\n",
       "      <td>0.733710</td>\n",
       "      <td>0.823329</td>\n",
       "      <td>0.798122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060538</td>\n",
       "      <td>0.036776</td>\n",
       "      <td>0.066461</td>\n",
       "      <td>0.063715</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.045069</td>\n",
       "      <td>0.057091</td>\n",
       "      <td>0.180714</td>\n",
       "      <td>0.141614</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FedProx μ = 2 LR</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.732787</td>\n",
       "      <td>0.875265</td>\n",
       "      <td>0.683155</td>\n",
       "      <td>0.632277</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196758</td>\n",
       "      <td>0.310230</td>\n",
       "      <td>0.400456</td>\n",
       "      <td>0.080055</td>\n",
       "      <td>0.324678</td>\n",
       "      <td>0.349235</td>\n",
       "      <td>0.378126</td>\n",
       "      <td>0.091933</td>\n",
       "      <td>0.146980</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FedProx μ = 2 MLP</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.764628</td>\n",
       "      <td>0.875014</td>\n",
       "      <td>0.735344</td>\n",
       "      <td>0.832388</td>\n",
       "      <td>0.788732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077297</td>\n",
       "      <td>0.055470</td>\n",
       "      <td>0.068422</td>\n",
       "      <td>0.063977</td>\n",
       "      <td>0.053735</td>\n",
       "      <td>0.055902</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.284808</td>\n",
       "      <td>0.186547</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FedAvg LR</td>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.811036</td>\n",
       "      <td>0.902844</td>\n",
       "      <td>0.789018</td>\n",
       "      <td>0.798415</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033706</td>\n",
       "      <td>0.028944</td>\n",
       "      <td>0.021820</td>\n",
       "      <td>0.048616</td>\n",
       "      <td>0.025394</td>\n",
       "      <td>0.020448</td>\n",
       "      <td>0.018776</td>\n",
       "      <td>0.184754</td>\n",
       "      <td>0.103482</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FedAvg MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.772265</td>\n",
       "      <td>0.879135</td>\n",
       "      <td>0.757130</td>\n",
       "      <td>0.823677</td>\n",
       "      <td>0.840376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063252</td>\n",
       "      <td>0.047105</td>\n",
       "      <td>0.046854</td>\n",
       "      <td>0.062625</td>\n",
       "      <td>0.044833</td>\n",
       "      <td>0.043445</td>\n",
       "      <td>0.044664</td>\n",
       "      <td>0.307924</td>\n",
       "      <td>0.161908</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FedAvg SGD</td>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.815227</td>\n",
       "      <td>0.905785</td>\n",
       "      <td>0.703605</td>\n",
       "      <td>0.889761</td>\n",
       "      <td>0.669014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032428</td>\n",
       "      <td>0.043430</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>0.037681</td>\n",
       "      <td>0.031788</td>\n",
       "      <td>0.027052</td>\n",
       "      <td>0.030723</td>\n",
       "      <td>0.078505</td>\n",
       "      <td>0.083446</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FedAvg XGBRF</td>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.808905</td>\n",
       "      <td>0.914091</td>\n",
       "      <td>0.775698</td>\n",
       "      <td>0.828831</td>\n",
       "      <td>0.866197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046115</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.063458</td>\n",
       "      <td>0.036673</td>\n",
       "      <td>0.032355</td>\n",
       "      <td>0.034117</td>\n",
       "      <td>0.048894</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.114768</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FedProx μ = 0.5 LR</td>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.744148</td>\n",
       "      <td>0.886173</td>\n",
       "      <td>0.697960</td>\n",
       "      <td>0.663375</td>\n",
       "      <td>0.776995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204832</td>\n",
       "      <td>0.325489</td>\n",
       "      <td>0.381419</td>\n",
       "      <td>0.075904</td>\n",
       "      <td>0.335106</td>\n",
       "      <td>0.350848</td>\n",
       "      <td>0.368452</td>\n",
       "      <td>0.098527</td>\n",
       "      <td>0.186515</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FedProx μ = 0.5 MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.766326</td>\n",
       "      <td>0.872857</td>\n",
       "      <td>0.763666</td>\n",
       "      <td>0.837517</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068345</td>\n",
       "      <td>0.047905</td>\n",
       "      <td>0.057038</td>\n",
       "      <td>0.069427</td>\n",
       "      <td>0.046722</td>\n",
       "      <td>0.047947</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.424614</td>\n",
       "      <td>0.172286</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FedProx μ = 2 LR</td>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.686387</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.617201</td>\n",
       "      <td>0.535782</td>\n",
       "      <td>0.615023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260728</td>\n",
       "      <td>0.415375</td>\n",
       "      <td>0.477102</td>\n",
       "      <td>0.095456</td>\n",
       "      <td>0.426345</td>\n",
       "      <td>0.443991</td>\n",
       "      <td>0.463249</td>\n",
       "      <td>0.156395</td>\n",
       "      <td>0.237972</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FedProx μ = 2 MLP</td>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.770113</td>\n",
       "      <td>0.879475</td>\n",
       "      <td>0.742276</td>\n",
       "      <td>0.820784</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068553</td>\n",
       "      <td>0.047328</td>\n",
       "      <td>0.055629</td>\n",
       "      <td>0.053469</td>\n",
       "      <td>0.047767</td>\n",
       "      <td>0.049644</td>\n",
       "      <td>0.052851</td>\n",
       "      <td>0.335895</td>\n",
       "      <td>0.164525</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FedAvg LR</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.632964</td>\n",
       "      <td>0.863672</td>\n",
       "      <td>0.533819</td>\n",
       "      <td>0.390794</td>\n",
       "      <td>0.478873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268345</td>\n",
       "      <td>0.428283</td>\n",
       "      <td>0.524882</td>\n",
       "      <td>0.100094</td>\n",
       "      <td>0.444639</td>\n",
       "      <td>0.471667</td>\n",
       "      <td>0.502211</td>\n",
       "      <td>0.114360</td>\n",
       "      <td>0.225208</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FedAvg MLP</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.774707</td>\n",
       "      <td>0.876632</td>\n",
       "      <td>0.730491</td>\n",
       "      <td>0.841119</td>\n",
       "      <td>0.767606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074492</td>\n",
       "      <td>0.058149</td>\n",
       "      <td>0.058242</td>\n",
       "      <td>0.067351</td>\n",
       "      <td>0.056162</td>\n",
       "      <td>0.055336</td>\n",
       "      <td>0.056577</td>\n",
       "      <td>0.210522</td>\n",
       "      <td>0.175010</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FedAvg SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.802238</td>\n",
       "      <td>0.893812</td>\n",
       "      <td>0.688701</td>\n",
       "      <td>0.880330</td>\n",
       "      <td>0.654930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062907</td>\n",
       "      <td>0.073455</td>\n",
       "      <td>0.045202</td>\n",
       "      <td>0.051712</td>\n",
       "      <td>0.060712</td>\n",
       "      <td>0.049954</td>\n",
       "      <td>0.045843</td>\n",
       "      <td>0.081803</td>\n",
       "      <td>0.153167</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FedAvg XGBRF</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.802694</td>\n",
       "      <td>0.902429</td>\n",
       "      <td>0.784264</td>\n",
       "      <td>0.832605</td>\n",
       "      <td>0.880282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057017</td>\n",
       "      <td>0.064899</td>\n",
       "      <td>0.046072</td>\n",
       "      <td>0.040640</td>\n",
       "      <td>0.051931</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>0.035123</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.163475</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FedProx μ = 0.5 LR</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.729441</td>\n",
       "      <td>0.878684</td>\n",
       "      <td>0.684492</td>\n",
       "      <td>0.638954</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199016</td>\n",
       "      <td>0.313325</td>\n",
       "      <td>0.394266</td>\n",
       "      <td>0.078925</td>\n",
       "      <td>0.326683</td>\n",
       "      <td>0.349057</td>\n",
       "      <td>0.374811</td>\n",
       "      <td>0.104882</td>\n",
       "      <td>0.184321</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FedProx μ = 0.5 MLP</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.748423</td>\n",
       "      <td>0.872036</td>\n",
       "      <td>0.711824</td>\n",
       "      <td>0.814700</td>\n",
       "      <td>0.772300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073813</td>\n",
       "      <td>0.050763</td>\n",
       "      <td>0.080376</td>\n",
       "      <td>0.054350</td>\n",
       "      <td>0.051698</td>\n",
       "      <td>0.059344</td>\n",
       "      <td>0.071269</td>\n",
       "      <td>0.279322</td>\n",
       "      <td>0.157086</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FedProx μ = 2 LR</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.753018</td>\n",
       "      <td>0.888145</td>\n",
       "      <td>0.686423</td>\n",
       "      <td>0.635934</td>\n",
       "      <td>0.814554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197957</td>\n",
       "      <td>0.311867</td>\n",
       "      <td>0.399505</td>\n",
       "      <td>0.092948</td>\n",
       "      <td>0.325949</td>\n",
       "      <td>0.349844</td>\n",
       "      <td>0.377888</td>\n",
       "      <td>0.140083</td>\n",
       "      <td>0.152752</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FedProx μ = 2 MLP</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>internal test</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.783732</td>\n",
       "      <td>0.881958</td>\n",
       "      <td>0.743910</td>\n",
       "      <td>0.837881</td>\n",
       "      <td>0.795775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066423</td>\n",
       "      <td>0.052268</td>\n",
       "      <td>0.052511</td>\n",
       "      <td>0.063760</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.047936</td>\n",
       "      <td>0.049812</td>\n",
       "      <td>0.282076</td>\n",
       "      <td>0.161349</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         algorithm_name  num_clients split_method       val_name  fold_idx  \\\n",
       "2             FedAvg LR            2      uniform  internal test       2.5   \n",
       "11           FedAvg MLP            2      uniform  internal test       2.5   \n",
       "20           FedAvg SGD            2      uniform  internal test       2.5   \n",
       "29         FedAvg XGBRF            2      uniform  internal test       2.5   \n",
       "38   FedProx μ = 0.5 LR            2      uniform  internal test       2.5   \n",
       "47  FedProx μ = 0.5 MLP            2      uniform  internal test       2.5   \n",
       "56     FedProx μ = 2 LR            2      uniform  internal test       2.5   \n",
       "65    FedProx μ = 2 MLP            2      uniform  internal test       2.5   \n",
       "3             FedAvg LR            4      uniform  internal test       2.5   \n",
       "12           FedAvg MLP            4      uniform  internal test       2.5   \n",
       "21           FedAvg SGD            4      uniform  internal test       2.5   \n",
       "30         FedAvg XGBRF            4      uniform  internal test       2.5   \n",
       "39   FedProx μ = 0.5 LR            4      uniform  internal test       2.5   \n",
       "48  FedProx μ = 0.5 MLP            4      uniform  internal test       2.5   \n",
       "57     FedProx μ = 2 LR            4      uniform  internal test       2.5   \n",
       "66    FedProx μ = 2 MLP            4      uniform  internal test       2.5   \n",
       "2             FedAvg LR            2      uniform  internal test       2.5   \n",
       "4            FedAvg MLP            2      uniform  internal test       2.5   \n",
       "6            FedAvg SGD            2      uniform  internal test       2.5   \n",
       "8          FedAvg XGBRF            2      uniform  internal test       2.5   \n",
       "10   FedProx μ = 0.5 LR            2      uniform  internal test       2.5   \n",
       "12  FedProx μ = 0.5 MLP            2      uniform  internal test       2.5   \n",
       "14     FedProx μ = 2 LR            2      uniform  internal test       2.5   \n",
       "16    FedProx μ = 2 MLP            2      uniform  internal test       2.5   \n",
       "3             FedAvg LR            4      uniform  internal test       2.5   \n",
       "5            FedAvg MLP            4      uniform  internal test       2.5   \n",
       "7            FedAvg SGD            4      uniform  internal test       2.5   \n",
       "9          FedAvg XGBRF            4      uniform  internal test       2.5   \n",
       "11   FedProx μ = 0.5 LR            4      uniform  internal test       2.5   \n",
       "13  FedProx μ = 0.5 MLP            4      uniform  internal test       2.5   \n",
       "15     FedProx μ = 2 LR            4      uniform  internal test       2.5   \n",
       "17    FedProx μ = 2 MLP            4      uniform  internal test       2.5   \n",
       "2             FedAvg LR            2       linear  internal test       2.5   \n",
       "4            FedAvg MLP            2       linear  internal test       2.5   \n",
       "6            FedAvg SGD            2       linear  internal test       2.5   \n",
       "8          FedAvg XGBRF            2       linear  internal test       2.5   \n",
       "10   FedProx μ = 0.5 LR            2       linear  internal test       2.5   \n",
       "12  FedProx μ = 0.5 MLP            2       linear  internal test       2.5   \n",
       "14     FedProx μ = 2 LR            2       linear  internal test       2.5   \n",
       "16    FedProx μ = 2 MLP            2       linear  internal test       2.5   \n",
       "3             FedAvg LR            4       linear  internal test       2.5   \n",
       "5            FedAvg MLP            4       linear  internal test       2.5   \n",
       "7            FedAvg SGD            4       linear  internal test       2.5   \n",
       "9          FedAvg XGBRF            4       linear  internal test       2.5   \n",
       "11   FedProx μ = 0.5 LR            4       linear  internal test       2.5   \n",
       "13  FedProx μ = 0.5 MLP            4       linear  internal test       2.5   \n",
       "15     FedProx μ = 2 LR            4       linear  internal test       2.5   \n",
       "17    FedProx μ = 2 MLP            4       linear  internal test       2.5   \n",
       "\n",
       "    roc_auc_score  auc_precision_recall  accuracy_score  precision_score  \\\n",
       "2        0.689773              0.873723        0.617201         0.533132   \n",
       "11       0.760004              0.872462        0.712220         0.816843   \n",
       "20       0.828008              0.919800        0.735294         0.904037   \n",
       "29       0.828651              0.924113        0.800505         0.847752   \n",
       "38       0.754560              0.887329        0.704595         0.671177   \n",
       "47       0.756737              0.871983        0.743712         0.829433   \n",
       "56       0.812445              0.906127        0.777332         0.790153   \n",
       "65       0.764644              0.868148        0.738562         0.830074   \n",
       "3        0.730323              0.876311        0.679739         0.629342   \n",
       "12       0.772909              0.876451        0.747128         0.836818   \n",
       "21       0.794320              0.897981        0.688305         0.882143   \n",
       "30       0.800313              0.901946        0.767380         0.824452   \n",
       "39       0.743017              0.885298        0.683106         0.633008   \n",
       "48       0.773893              0.876254        0.750297         0.837511   \n",
       "57       0.732059              0.878554        0.684740         0.639297   \n",
       "66       0.753508              0.866042        0.740394         0.831352   \n",
       "2        0.727821              0.876881        0.696376         0.660803   \n",
       "4        0.767768              0.877249        0.740295         0.827109   \n",
       "6        0.816022              0.907412        0.703506         0.882674   \n",
       "8        0.785955              0.904351        0.751783         0.839760   \n",
       "10       0.692778              0.872303        0.622252         0.528627   \n",
       "12       0.777823              0.882572        0.738810         0.838934   \n",
       "14       0.637324              0.865954        0.528768         0.391762   \n",
       "16       0.747496              0.867655        0.718657         0.821718   \n",
       "3        0.676108              0.860770        0.612250         0.513581   \n",
       "5        0.766897              0.875666        0.726827         0.827184   \n",
       "7        0.795923              0.896941        0.694890         0.895564   \n",
       "9        0.825733              0.922086        0.779065         0.802731   \n",
       "11       0.621311              0.855088        0.527085         0.385972   \n",
       "13       0.765415              0.877384        0.733710         0.823329   \n",
       "15       0.732787              0.875265        0.683155         0.632277   \n",
       "17       0.764628              0.875014        0.735344         0.832388   \n",
       "2        0.811036              0.902844        0.789018         0.798415   \n",
       "4        0.772265              0.879135        0.757130         0.823677   \n",
       "6        0.815227              0.905785        0.703605         0.889761   \n",
       "8        0.808905              0.914091        0.775698         0.828831   \n",
       "10       0.744148              0.886173        0.697960         0.663375   \n",
       "12       0.766326              0.872857        0.763666         0.837517   \n",
       "14       0.686387              0.875048        0.617201         0.535782   \n",
       "16       0.770113              0.879475        0.742276         0.820784   \n",
       "3        0.632964              0.863672        0.533819         0.390794   \n",
       "5        0.774707              0.876632        0.730491         0.841119   \n",
       "7        0.802238              0.893812        0.688701         0.880330   \n",
       "9        0.802694              0.902429        0.784264         0.832605   \n",
       "11       0.729441              0.878684        0.684492         0.638954   \n",
       "13       0.748423              0.872036        0.711824         0.814700   \n",
       "15       0.753018              0.888145        0.686423         0.635934   \n",
       "17       0.783732              0.881958        0.743910         0.837881   \n",
       "\n",
       "    recall_score  ...  accuracy_score_std  precision_score_std  \\\n",
       "2       0.622066  ...            0.261588             0.414227   \n",
       "11      0.767606  ...            0.083873             0.051478   \n",
       "20      0.706573  ...            0.029390             0.048977   \n",
       "29      0.882629  ...            0.024691             0.042688   \n",
       "38      0.774648  ...            0.208265             0.329532   \n",
       "47      0.807512  ...            0.074669             0.047859   \n",
       "56      0.936620  ...            0.023524             0.014448   \n",
       "65      0.798122  ...            0.053685             0.042344   \n",
       "3       0.816901  ...            0.195043             0.308643   \n",
       "12      0.805164  ...            0.064906             0.054659   \n",
       "21      0.652582  ...            0.047382             0.058454   \n",
       "30      0.859155  ...            0.054478             0.050176   \n",
       "39      0.814554  ...            0.197443             0.310578   \n",
       "48      0.805164  ...            0.088255             0.050764   \n",
       "57      0.802817  ...            0.198510             0.313732   \n",
       "66      0.798122  ...            0.068732             0.047940   \n",
       "2       0.779343  ...            0.203317             0.324156   \n",
       "4       0.805164  ...            0.068286             0.050626   \n",
       "6       0.678404  ...            0.046347             0.065495   \n",
       "8       0.812207  ...            0.033173             0.048316   \n",
       "10      0.638498  ...            0.263720             0.409569   \n",
       "12      0.786385  ...            0.062510             0.049365   \n",
       "14      0.467136  ...            0.262370             0.429278   \n",
       "16      0.774648  ...            0.069853             0.047807   \n",
       "3       0.652582  ...            0.255731             0.398047   \n",
       "5       0.784038  ...            0.052383             0.048336   \n",
       "7       0.654930  ...            0.035698             0.064737   \n",
       "9       0.917840  ...            0.061004             0.045157   \n",
       "11      0.476526  ...            0.260635             0.422970   \n",
       "13      0.798122  ...            0.060538             0.036776   \n",
       "15      0.816901  ...            0.196758             0.310230   \n",
       "17      0.788732  ...            0.077297             0.055470   \n",
       "2       0.943662  ...            0.033706             0.028944   \n",
       "4       0.840376  ...            0.063252             0.047105   \n",
       "6       0.669014  ...            0.032428             0.043430   \n",
       "8       0.866197  ...            0.046115             0.037900   \n",
       "10      0.776995  ...            0.204832             0.325489   \n",
       "12      0.830986  ...            0.068345             0.047905   \n",
       "14      0.615023  ...            0.260728             0.415375   \n",
       "16      0.816901  ...            0.068553             0.047328   \n",
       "3       0.478873  ...            0.268345             0.428283   \n",
       "5       0.767606  ...            0.074492             0.058149   \n",
       "7       0.654930  ...            0.062907             0.073455   \n",
       "9       0.880282  ...            0.057017             0.064899   \n",
       "11      0.802817  ...            0.199016             0.313325   \n",
       "13      0.772300  ...            0.073813             0.050763   \n",
       "15      0.814554  ...            0.197957             0.311867   \n",
       "17      0.795775  ...            0.066423             0.052268   \n",
       "\n",
       "    recall_score_std  average_precision_score_std  fbeta_score_0.5_std  \\\n",
       "2           0.482046                     0.094197             0.425912   \n",
       "11          0.088520                     0.068716             0.055323   \n",
       "20          0.032628                     0.024662             0.032386   \n",
       "29          0.036366                     0.018673             0.028679   \n",
       "38          0.379707                     0.081846             0.338324   \n",
       "47          0.075410                     0.059007             0.048029   \n",
       "56          0.024798                     0.039429             0.014663   \n",
       "65          0.045129                     0.057369             0.038986   \n",
       "3           0.400456                     0.077422             0.323346   \n",
       "12          0.058695                     0.066108             0.047701   \n",
       "21          0.032931                     0.042840             0.045213   \n",
       "30          0.035631                     0.055826             0.043288   \n",
       "39          0.399505                     0.080489             0.324926   \n",
       "48          0.082327                     0.060135             0.055450   \n",
       "57          0.393964                     0.078936             0.326886   \n",
       "66          0.053940                     0.068713             0.047947   \n",
       "2           0.382898                     0.072955             0.334020   \n",
       "4           0.049929                     0.062655             0.048739   \n",
       "6           0.048313                     0.048111             0.045812   \n",
       "8           0.053940                     0.043312             0.032505   \n",
       "10          0.495139                     0.096837             0.424166   \n",
       "12          0.063250                     0.063901             0.044433   \n",
       "14          0.511903                     0.097544             0.443571   \n",
       "16          0.075059                     0.065736             0.046528   \n",
       "3           0.505684                     0.086246             0.415656   \n",
       "5           0.055391                     0.064580             0.039184   \n",
       "7           0.061554                     0.048059             0.036401   \n",
       "9           0.055212                     0.031522             0.041620   \n",
       "11          0.522109                     0.089368             0.439663   \n",
       "13          0.066461                     0.063715             0.037632   \n",
       "15          0.400456                     0.080055             0.324678   \n",
       "17          0.068422                     0.063977             0.053735   \n",
       "2           0.021820                     0.048616             0.025394   \n",
       "4           0.046854                     0.062625             0.044833   \n",
       "6           0.034211                     0.037681             0.031788   \n",
       "8           0.063458                     0.036673             0.032355   \n",
       "10          0.381419                     0.075904             0.335106   \n",
       "12          0.057038                     0.069427             0.046722   \n",
       "14          0.477102                     0.095456             0.426345   \n",
       "16          0.055629                     0.053469             0.047767   \n",
       "3           0.524882                     0.100094             0.444639   \n",
       "5           0.058242                     0.067351             0.056162   \n",
       "7           0.045202                     0.051712             0.060712   \n",
       "9           0.046072                     0.040640             0.051931   \n",
       "11          0.394266                     0.078925             0.326683   \n",
       "13          0.080376                     0.054350             0.051698   \n",
       "15          0.399505                     0.092948             0.325949   \n",
       "17          0.052511                     0.063760             0.049341   \n",
       "\n",
       "    fbeta_score_1_std fbeta_score_2_std  log_loss_std matthews_corrcoef_std  \\\n",
       "2            0.445021          0.466358      0.139675              0.249825   \n",
       "11           0.065779          0.079040      0.308273              0.179210   \n",
       "20           0.021951          0.026878      0.032096              0.083677   \n",
       "29           0.013386          0.023111      0.000147              0.088943   \n",
       "38           0.352573          0.368288      0.154714              0.198308   \n",
       "47           0.054443          0.066003      0.313834              0.181533   \n",
       "56           0.016530          0.020675      0.137376              0.068946   \n",
       "65           0.037932          0.041217      0.367971              0.133159   \n",
       "3            0.348354          0.377765      0.110126              0.147557   \n",
       "12           0.045198          0.051454      0.261040              0.170983   \n",
       "21           0.034710          0.032208      0.058866              0.120626   \n",
       "30           0.035383          0.033022      0.000281              0.153223   \n",
       "39           0.349234          0.377673      0.119413              0.164419   \n",
       "48           0.064441          0.074882      0.248645              0.204304   \n",
       "57           0.348984          0.374546      0.107227              0.170084   \n",
       "66           0.049266          0.051786      0.253359              0.164822   \n",
       "2            0.350372          0.368974      0.130071              0.177841   \n",
       "4            0.047565          0.048376      0.228905              0.172388   \n",
       "6            0.036258          0.042201      0.071575              0.122341   \n",
       "8            0.022274          0.038089      0.000156              0.109365   \n",
       "10           0.448186          0.475187      0.147971              0.241376   \n",
       "12           0.046271          0.055405      0.298565              0.150623   \n",
       "14           0.466914          0.492891      0.140463              0.203402   \n",
       "16           0.052884          0.065264      0.248833              0.163476   \n",
       "3            0.445282          0.479599      0.106602              0.215334   \n",
       "5            0.037624          0.046877      0.284105              0.140174   \n",
       "7            0.032085          0.050195      0.059499              0.105628   \n",
       "9            0.040141          0.046249      0.000261              0.183375   \n",
       "11           0.467333          0.498724      0.095420              0.195162   \n",
       "13           0.045069          0.057091      0.180714              0.141614   \n",
       "15           0.349235          0.378126      0.091933              0.146980   \n",
       "17           0.055902          0.062471      0.284808              0.186547   \n",
       "2            0.020448          0.018776      0.184754              0.103482   \n",
       "4            0.043445          0.044664      0.307924              0.161908   \n",
       "6            0.027052          0.030723      0.078505              0.083446   \n",
       "8            0.034117          0.048894      0.000323              0.114768   \n",
       "10           0.350848          0.368452      0.098527              0.186515   \n",
       "12           0.047947          0.052500      0.424614              0.172286   \n",
       "14           0.443991          0.463249      0.156395              0.237972   \n",
       "16           0.049644          0.052851      0.335895              0.164525   \n",
       "3            0.471667          0.502211      0.114360              0.225208   \n",
       "5            0.055336          0.056577      0.210522              0.175010   \n",
       "7            0.049954          0.045843      0.081803              0.153167   \n",
       "9            0.036133          0.035123      0.000234              0.163475   \n",
       "11           0.349057          0.374811      0.104882              0.184321   \n",
       "13           0.059344          0.071269      0.279322              0.157086   \n",
       "15           0.349844          0.377888      0.140083              0.152752   \n",
       "17           0.047936          0.049812      0.282076              0.161349   \n",
       "\n",
       "   stratified  \n",
       "2        True  \n",
       "11       True  \n",
       "20       True  \n",
       "29       True  \n",
       "38       True  \n",
       "47       True  \n",
       "56       True  \n",
       "65       True  \n",
       "3        True  \n",
       "12       True  \n",
       "21       True  \n",
       "30       True  \n",
       "39       True  \n",
       "48       True  \n",
       "57       True  \n",
       "66       True  \n",
       "2       False  \n",
       "4       False  \n",
       "6       False  \n",
       "8       False  \n",
       "10      False  \n",
       "12      False  \n",
       "14      False  \n",
       "16      False  \n",
       "3       False  \n",
       "5       False  \n",
       "7       False  \n",
       "9       False  \n",
       "11      False  \n",
       "13      False  \n",
       "15      False  \n",
       "17      False  \n",
       "2       False  \n",
       "4       False  \n",
       "6       False  \n",
       "8       False  \n",
       "10      False  \n",
       "12      False  \n",
       "14      False  \n",
       "16      False  \n",
       "3       False  \n",
       "5       False  \n",
       "7       False  \n",
       "9       False  \n",
       "11      False  \n",
       "13      False  \n",
       "15      False  \n",
       "17      False  \n",
       "\n",
       "[48 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split_method\n",
       "uniform    32\n",
       "linear     16\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "stratified\n",
       "False    32\n",
       "True     16\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(tables['split_method'].value_counts())\n",
    "display(tables['stratified'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# bar_width = 0.35\n",
    "# group_centers = []\n",
    "\n",
    "# _, ax = plt.subplots()\n",
    "\n",
    "# t = tables[tables['num_clients'] == 2]\n",
    "\n",
    "# ax.bar(0.5, score, bar_width, label='Uniform Random', color='b', yerr=error, align='edge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False linear\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>auc_precision_recall</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>average_precision_score</th>\n",
       "      <th>fbeta_score_0.5</th>\n",
       "      <th>fbeta_score_1</th>\n",
       "      <th>fbeta_score_2</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>...</th>\n",
       "      <th>auc_precision_recall_std</th>\n",
       "      <th>accuracy_score_std</th>\n",
       "      <th>precision_score_std</th>\n",
       "      <th>recall_score_std</th>\n",
       "      <th>average_precision_score_std</th>\n",
       "      <th>fbeta_score_0.5_std</th>\n",
       "      <th>fbeta_score_1_std</th>\n",
       "      <th>fbeta_score_2_std</th>\n",
       "      <th>log_loss_std</th>\n",
       "      <th>matthews_corrcoef_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FedAvg LR</th>\n",
       "      <td>0.811036</td>\n",
       "      <td>0.902844</td>\n",
       "      <td>0.789018</td>\n",
       "      <td>0.798415</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.823617</td>\n",
       "      <td>0.864697</td>\n",
       "      <td>0.910318</td>\n",
       "      <td>0.603108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049306</td>\n",
       "      <td>0.033706</td>\n",
       "      <td>0.028944</td>\n",
       "      <td>0.021820</td>\n",
       "      <td>0.048616</td>\n",
       "      <td>0.025394</td>\n",
       "      <td>0.020448</td>\n",
       "      <td>0.018776</td>\n",
       "      <td>0.184754</td>\n",
       "      <td>0.103482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedAvg MLP</th>\n",
       "      <td>0.772265</td>\n",
       "      <td>0.879135</td>\n",
       "      <td>0.757130</td>\n",
       "      <td>0.823677</td>\n",
       "      <td>0.840376</td>\n",
       "      <td>0.881071</td>\n",
       "      <td>0.826757</td>\n",
       "      <td>0.831619</td>\n",
       "      <td>0.836773</td>\n",
       "      <td>0.751361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.063252</td>\n",
       "      <td>0.047105</td>\n",
       "      <td>0.046854</td>\n",
       "      <td>0.062625</td>\n",
       "      <td>0.044833</td>\n",
       "      <td>0.043445</td>\n",
       "      <td>0.044664</td>\n",
       "      <td>0.307924</td>\n",
       "      <td>0.161908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedAvg SGD</th>\n",
       "      <td>0.815227</td>\n",
       "      <td>0.905785</td>\n",
       "      <td>0.703605</td>\n",
       "      <td>0.889761</td>\n",
       "      <td>0.669014</td>\n",
       "      <td>0.907035</td>\n",
       "      <td>0.833970</td>\n",
       "      <td>0.762919</td>\n",
       "      <td>0.703527</td>\n",
       "      <td>0.591060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038386</td>\n",
       "      <td>0.032428</td>\n",
       "      <td>0.043430</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>0.037681</td>\n",
       "      <td>0.031788</td>\n",
       "      <td>0.027052</td>\n",
       "      <td>0.030723</td>\n",
       "      <td>0.078505</td>\n",
       "      <td>0.083446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedAvg XGBRF</th>\n",
       "      <td>0.808905</td>\n",
       "      <td>0.914091</td>\n",
       "      <td>0.775698</td>\n",
       "      <td>0.828831</td>\n",
       "      <td>0.866197</td>\n",
       "      <td>0.904015</td>\n",
       "      <td>0.835266</td>\n",
       "      <td>0.845804</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>0.690981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031693</td>\n",
       "      <td>0.046115</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.063458</td>\n",
       "      <td>0.036673</td>\n",
       "      <td>0.032355</td>\n",
       "      <td>0.034117</td>\n",
       "      <td>0.048894</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.114768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedProx μ = 0.5 LR</th>\n",
       "      <td>0.744148</td>\n",
       "      <td>0.886173</td>\n",
       "      <td>0.697960</td>\n",
       "      <td>0.663375</td>\n",
       "      <td>0.776995</td>\n",
       "      <td>0.863887</td>\n",
       "      <td>0.683252</td>\n",
       "      <td>0.715507</td>\n",
       "      <td>0.751114</td>\n",
       "      <td>0.616646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028525</td>\n",
       "      <td>0.204832</td>\n",
       "      <td>0.325489</td>\n",
       "      <td>0.381419</td>\n",
       "      <td>0.075904</td>\n",
       "      <td>0.335106</td>\n",
       "      <td>0.350848</td>\n",
       "      <td>0.368452</td>\n",
       "      <td>0.098527</td>\n",
       "      <td>0.186515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedProx μ = 0.5 MLP</th>\n",
       "      <td>0.766326</td>\n",
       "      <td>0.872857</td>\n",
       "      <td>0.763666</td>\n",
       "      <td>0.837517</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.874971</td>\n",
       "      <td>0.835858</td>\n",
       "      <td>0.833701</td>\n",
       "      <td>0.831940</td>\n",
       "      <td>0.935986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071320</td>\n",
       "      <td>0.068345</td>\n",
       "      <td>0.047905</td>\n",
       "      <td>0.057038</td>\n",
       "      <td>0.069427</td>\n",
       "      <td>0.046722</td>\n",
       "      <td>0.047947</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.424614</td>\n",
       "      <td>0.172286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedProx μ = 2 LR</th>\n",
       "      <td>0.686387</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.617201</td>\n",
       "      <td>0.535782</td>\n",
       "      <td>0.615023</td>\n",
       "      <td>0.829031</td>\n",
       "      <td>0.549921</td>\n",
       "      <td>0.572616</td>\n",
       "      <td>0.597311</td>\n",
       "      <td>0.667313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042750</td>\n",
       "      <td>0.260728</td>\n",
       "      <td>0.415375</td>\n",
       "      <td>0.477102</td>\n",
       "      <td>0.095456</td>\n",
       "      <td>0.426345</td>\n",
       "      <td>0.443991</td>\n",
       "      <td>0.463249</td>\n",
       "      <td>0.156395</td>\n",
       "      <td>0.237972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedProx μ = 2 MLP</th>\n",
       "      <td>0.770113</td>\n",
       "      <td>0.879475</td>\n",
       "      <td>0.742276</td>\n",
       "      <td>0.820784</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.881897</td>\n",
       "      <td>0.819857</td>\n",
       "      <td>0.818608</td>\n",
       "      <td>0.817528</td>\n",
       "      <td>0.907679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056045</td>\n",
       "      <td>0.068553</td>\n",
       "      <td>0.047328</td>\n",
       "      <td>0.055629</td>\n",
       "      <td>0.053469</td>\n",
       "      <td>0.047767</td>\n",
       "      <td>0.049644</td>\n",
       "      <td>0.052851</td>\n",
       "      <td>0.335895</td>\n",
       "      <td>0.164525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     roc_auc_score  auc_precision_recall  accuracy_score  \\\n",
       "algorithm_name                                                             \n",
       "FedAvg LR                 0.811036              0.902844        0.789018   \n",
       "FedAvg MLP                0.772265              0.879135        0.757130   \n",
       "FedAvg SGD                0.815227              0.905785        0.703605   \n",
       "FedAvg XGBRF              0.808905              0.914091        0.775698   \n",
       "FedProx μ = 0.5 LR        0.744148              0.886173        0.697960   \n",
       "FedProx μ = 0.5 MLP       0.766326              0.872857        0.763666   \n",
       "FedProx μ = 2 LR          0.686387              0.875048        0.617201   \n",
       "FedProx μ = 2 MLP         0.770113              0.879475        0.742276   \n",
       "\n",
       "                     precision_score  recall_score  average_precision_score  \\\n",
       "algorithm_name                                                                \n",
       "FedAvg LR                   0.798415      0.943662                 0.904118   \n",
       "FedAvg MLP                  0.823677      0.840376                 0.881071   \n",
       "FedAvg SGD                  0.889761      0.669014                 0.907035   \n",
       "FedAvg XGBRF                0.828831      0.866197                 0.904015   \n",
       "FedProx μ = 0.5 LR          0.663375      0.776995                 0.863887   \n",
       "FedProx μ = 0.5 MLP         0.837517      0.830986                 0.874971   \n",
       "FedProx μ = 2 LR            0.535782      0.615023                 0.829031   \n",
       "FedProx μ = 2 MLP           0.820784      0.816901                 0.881897   \n",
       "\n",
       "                     fbeta_score_0.5  fbeta_score_1  fbeta_score_2  log_loss  \\\n",
       "algorithm_name                                                                 \n",
       "FedAvg LR                   0.823617       0.864697       0.910318  0.603108   \n",
       "FedAvg MLP                  0.826757       0.831619       0.836773  0.751361   \n",
       "FedAvg SGD                  0.833970       0.762919       0.703527  0.591060   \n",
       "FedAvg XGBRF                0.835266       0.845804       0.857566  0.690981   \n",
       "FedProx μ = 0.5 LR          0.683252       0.715507       0.751114  0.616646   \n",
       "FedProx μ = 0.5 MLP         0.835858       0.833701       0.831940  0.935986   \n",
       "FedProx μ = 2 LR            0.549921       0.572616       0.597311  0.667313   \n",
       "FedProx μ = 2 MLP           0.819857       0.818608       0.817528  0.907679   \n",
       "\n",
       "                     ...  auc_precision_recall_std  accuracy_score_std  \\\n",
       "algorithm_name       ...                                                 \n",
       "FedAvg LR            ...                  0.049306            0.033706   \n",
       "FedAvg MLP           ...                  0.064275            0.063252   \n",
       "FedAvg SGD           ...                  0.038386            0.032428   \n",
       "FedAvg XGBRF         ...                  0.031693            0.046115   \n",
       "FedProx μ = 0.5 LR   ...                  0.028525            0.204832   \n",
       "FedProx μ = 0.5 MLP  ...                  0.071320            0.068345   \n",
       "FedProx μ = 2 LR     ...                  0.042750            0.260728   \n",
       "FedProx μ = 2 MLP    ...                  0.056045            0.068553   \n",
       "\n",
       "                     precision_score_std  recall_score_std  \\\n",
       "algorithm_name                                               \n",
       "FedAvg LR                       0.028944          0.021820   \n",
       "FedAvg MLP                      0.047105          0.046854   \n",
       "FedAvg SGD                      0.043430          0.034211   \n",
       "FedAvg XGBRF                    0.037900          0.063458   \n",
       "FedProx μ = 0.5 LR              0.325489          0.381419   \n",
       "FedProx μ = 0.5 MLP             0.047905          0.057038   \n",
       "FedProx μ = 2 LR                0.415375          0.477102   \n",
       "FedProx μ = 2 MLP               0.047328          0.055629   \n",
       "\n",
       "                     average_precision_score_std  fbeta_score_0.5_std  \\\n",
       "algorithm_name                                                          \n",
       "FedAvg LR                               0.048616             0.025394   \n",
       "FedAvg MLP                              0.062625             0.044833   \n",
       "FedAvg SGD                              0.037681             0.031788   \n",
       "FedAvg XGBRF                            0.036673             0.032355   \n",
       "FedProx μ = 0.5 LR                      0.075904             0.335106   \n",
       "FedProx μ = 0.5 MLP                     0.069427             0.046722   \n",
       "FedProx μ = 2 LR                        0.095456             0.426345   \n",
       "FedProx μ = 2 MLP                       0.053469             0.047767   \n",
       "\n",
       "                     fbeta_score_1_std  fbeta_score_2_std  log_loss_std  \\\n",
       "algorithm_name                                                            \n",
       "FedAvg LR                     0.020448           0.018776      0.184754   \n",
       "FedAvg MLP                    0.043445           0.044664      0.307924   \n",
       "FedAvg SGD                    0.027052           0.030723      0.078505   \n",
       "FedAvg XGBRF                  0.034117           0.048894      0.000323   \n",
       "FedProx μ = 0.5 LR            0.350848           0.368452      0.098527   \n",
       "FedProx μ = 0.5 MLP           0.047947           0.052500      0.424614   \n",
       "FedProx μ = 2 LR              0.443991           0.463249      0.156395   \n",
       "FedProx μ = 2 MLP             0.049644           0.052851      0.335895   \n",
       "\n",
       "                     matthews_corrcoef_std  \n",
       "algorithm_name                              \n",
       "FedAvg LR                         0.103482  \n",
       "FedAvg MLP                        0.161908  \n",
       "FedAvg SGD                        0.083446  \n",
       "FedAvg XGBRF                      0.114768  \n",
       "FedProx μ = 0.5 LR                0.186515  \n",
       "FedProx μ = 0.5 MLP               0.172286  \n",
       "FedProx μ = 2 LR                  0.237972  \n",
       "FedProx μ = 2 MLP                 0.164525  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "roc_auc_score                  float64\n",
       "auc_precision_recall           float64\n",
       "accuracy_score                 float64\n",
       "precision_score                float64\n",
       "recall_score                   float64\n",
       "average_precision_score        float64\n",
       "fbeta_score_0.5                float64\n",
       "fbeta_score_1                  float64\n",
       "fbeta_score_2                  float64\n",
       "log_loss                       float64\n",
       "matthews_corrcoef              float64\n",
       "roc_auc_score_std              float64\n",
       "auc_precision_recall_std       float64\n",
       "accuracy_score_std             float64\n",
       "precision_score_std            float64\n",
       "recall_score_std               float64\n",
       "average_precision_score_std    float64\n",
       "fbeta_score_0.5_std            float64\n",
       "fbeta_score_1_std              float64\n",
       "fbeta_score_2_std              float64\n",
       "log_loss_std                   float64\n",
       "matthews_corrcoef_std          float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False uniform\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>auc_precision_recall</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>average_precision_score</th>\n",
       "      <th>fbeta_score_0.5</th>\n",
       "      <th>fbeta_score_1</th>\n",
       "      <th>fbeta_score_2</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>...</th>\n",
       "      <th>auc_precision_recall_std</th>\n",
       "      <th>accuracy_score_std</th>\n",
       "      <th>precision_score_std</th>\n",
       "      <th>recall_score_std</th>\n",
       "      <th>average_precision_score_std</th>\n",
       "      <th>fbeta_score_0.5_std</th>\n",
       "      <th>fbeta_score_1_std</th>\n",
       "      <th>fbeta_score_2_std</th>\n",
       "      <th>log_loss_std</th>\n",
       "      <th>matthews_corrcoef_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FedAvg LR</th>\n",
       "      <td>0.727821</td>\n",
       "      <td>0.876881</td>\n",
       "      <td>0.696376</td>\n",
       "      <td>0.660803</td>\n",
       "      <td>0.779343</td>\n",
       "      <td>0.854909</td>\n",
       "      <td>0.681336</td>\n",
       "      <td>0.714833</td>\n",
       "      <td>0.752081</td>\n",
       "      <td>0.685130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030054</td>\n",
       "      <td>0.203317</td>\n",
       "      <td>0.324156</td>\n",
       "      <td>0.382898</td>\n",
       "      <td>0.072955</td>\n",
       "      <td>0.334020</td>\n",
       "      <td>0.350372</td>\n",
       "      <td>0.368974</td>\n",
       "      <td>0.130071</td>\n",
       "      <td>0.177841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedAvg MLP</th>\n",
       "      <td>0.767768</td>\n",
       "      <td>0.877249</td>\n",
       "      <td>0.740295</td>\n",
       "      <td>0.827109</td>\n",
       "      <td>0.805164</td>\n",
       "      <td>0.879119</td>\n",
       "      <td>0.822436</td>\n",
       "      <td>0.815699</td>\n",
       "      <td>0.809277</td>\n",
       "      <td>0.815437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064040</td>\n",
       "      <td>0.068286</td>\n",
       "      <td>0.050626</td>\n",
       "      <td>0.049929</td>\n",
       "      <td>0.062655</td>\n",
       "      <td>0.048739</td>\n",
       "      <td>0.047565</td>\n",
       "      <td>0.048376</td>\n",
       "      <td>0.228905</td>\n",
       "      <td>0.172388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedAvg SGD</th>\n",
       "      <td>0.816022</td>\n",
       "      <td>0.907412</td>\n",
       "      <td>0.703506</td>\n",
       "      <td>0.882674</td>\n",
       "      <td>0.678404</td>\n",
       "      <td>0.908697</td>\n",
       "      <td>0.831020</td>\n",
       "      <td>0.765352</td>\n",
       "      <td>0.710409</td>\n",
       "      <td>0.569328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049232</td>\n",
       "      <td>0.046347</td>\n",
       "      <td>0.065495</td>\n",
       "      <td>0.048313</td>\n",
       "      <td>0.048111</td>\n",
       "      <td>0.045812</td>\n",
       "      <td>0.036258</td>\n",
       "      <td>0.042201</td>\n",
       "      <td>0.071575</td>\n",
       "      <td>0.122341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedAvg XGBRF</th>\n",
       "      <td>0.785955</td>\n",
       "      <td>0.904351</td>\n",
       "      <td>0.751783</td>\n",
       "      <td>0.839760</td>\n",
       "      <td>0.812207</td>\n",
       "      <td>0.890341</td>\n",
       "      <td>0.832698</td>\n",
       "      <td>0.823611</td>\n",
       "      <td>0.816225</td>\n",
       "      <td>0.691065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033034</td>\n",
       "      <td>0.033173</td>\n",
       "      <td>0.048316</td>\n",
       "      <td>0.053940</td>\n",
       "      <td>0.043312</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>0.022274</td>\n",
       "      <td>0.038089</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.109365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedProx μ = 0.5 LR</th>\n",
       "      <td>0.692778</td>\n",
       "      <td>0.872303</td>\n",
       "      <td>0.622252</td>\n",
       "      <td>0.528627</td>\n",
       "      <td>0.638498</td>\n",
       "      <td>0.827288</td>\n",
       "      <td>0.547434</td>\n",
       "      <td>0.578328</td>\n",
       "      <td>0.612968</td>\n",
       "      <td>0.670539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049276</td>\n",
       "      <td>0.263720</td>\n",
       "      <td>0.409569</td>\n",
       "      <td>0.495139</td>\n",
       "      <td>0.096837</td>\n",
       "      <td>0.424166</td>\n",
       "      <td>0.448186</td>\n",
       "      <td>0.475187</td>\n",
       "      <td>0.147971</td>\n",
       "      <td>0.241376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedProx μ = 0.5 MLP</th>\n",
       "      <td>0.777823</td>\n",
       "      <td>0.882572</td>\n",
       "      <td>0.738810</td>\n",
       "      <td>0.838934</td>\n",
       "      <td>0.786385</td>\n",
       "      <td>0.884402</td>\n",
       "      <td>0.827055</td>\n",
       "      <td>0.810630</td>\n",
       "      <td>0.795659</td>\n",
       "      <td>0.881051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065543</td>\n",
       "      <td>0.062510</td>\n",
       "      <td>0.049365</td>\n",
       "      <td>0.063250</td>\n",
       "      <td>0.063901</td>\n",
       "      <td>0.044433</td>\n",
       "      <td>0.046271</td>\n",
       "      <td>0.055405</td>\n",
       "      <td>0.298565</td>\n",
       "      <td>0.150623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedProx μ = 2 LR</th>\n",
       "      <td>0.637324</td>\n",
       "      <td>0.865954</td>\n",
       "      <td>0.528768</td>\n",
       "      <td>0.391762</td>\n",
       "      <td>0.467136</td>\n",
       "      <td>0.794701</td>\n",
       "      <td>0.404814</td>\n",
       "      <td>0.426119</td>\n",
       "      <td>0.449810</td>\n",
       "      <td>0.690481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032972</td>\n",
       "      <td>0.262370</td>\n",
       "      <td>0.429278</td>\n",
       "      <td>0.511903</td>\n",
       "      <td>0.097544</td>\n",
       "      <td>0.443571</td>\n",
       "      <td>0.466914</td>\n",
       "      <td>0.492891</td>\n",
       "      <td>0.140463</td>\n",
       "      <td>0.203402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedProx μ = 2 MLP</th>\n",
       "      <td>0.747496</td>\n",
       "      <td>0.867655</td>\n",
       "      <td>0.718657</td>\n",
       "      <td>0.821718</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.869446</td>\n",
       "      <td>0.810961</td>\n",
       "      <td>0.796162</td>\n",
       "      <td>0.782814</td>\n",
       "      <td>0.758507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067098</td>\n",
       "      <td>0.069853</td>\n",
       "      <td>0.047807</td>\n",
       "      <td>0.075059</td>\n",
       "      <td>0.065736</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.052884</td>\n",
       "      <td>0.065264</td>\n",
       "      <td>0.248833</td>\n",
       "      <td>0.163476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     roc_auc_score  auc_precision_recall  accuracy_score  \\\n",
       "algorithm_name                                                             \n",
       "FedAvg LR                 0.727821              0.876881        0.696376   \n",
       "FedAvg MLP                0.767768              0.877249        0.740295   \n",
       "FedAvg SGD                0.816022              0.907412        0.703506   \n",
       "FedAvg XGBRF              0.785955              0.904351        0.751783   \n",
       "FedProx μ = 0.5 LR        0.692778              0.872303        0.622252   \n",
       "FedProx μ = 0.5 MLP       0.777823              0.882572        0.738810   \n",
       "FedProx μ = 2 LR          0.637324              0.865954        0.528768   \n",
       "FedProx μ = 2 MLP         0.747496              0.867655        0.718657   \n",
       "\n",
       "                     precision_score  recall_score  average_precision_score  \\\n",
       "algorithm_name                                                                \n",
       "FedAvg LR                   0.660803      0.779343                 0.854909   \n",
       "FedAvg MLP                  0.827109      0.805164                 0.879119   \n",
       "FedAvg SGD                  0.882674      0.678404                 0.908697   \n",
       "FedAvg XGBRF                0.839760      0.812207                 0.890341   \n",
       "FedProx μ = 0.5 LR          0.528627      0.638498                 0.827288   \n",
       "FedProx μ = 0.5 MLP         0.838934      0.786385                 0.884402   \n",
       "FedProx μ = 2 LR            0.391762      0.467136                 0.794701   \n",
       "FedProx μ = 2 MLP           0.821718      0.774648                 0.869446   \n",
       "\n",
       "                     fbeta_score_0.5  fbeta_score_1  fbeta_score_2  log_loss  \\\n",
       "algorithm_name                                                                 \n",
       "FedAvg LR                   0.681336       0.714833       0.752081  0.685130   \n",
       "FedAvg MLP                  0.822436       0.815699       0.809277  0.815437   \n",
       "FedAvg SGD                  0.831020       0.765352       0.710409  0.569328   \n",
       "FedAvg XGBRF                0.832698       0.823611       0.816225  0.691065   \n",
       "FedProx μ = 0.5 LR          0.547434       0.578328       0.612968  0.670539   \n",
       "FedProx μ = 0.5 MLP         0.827055       0.810630       0.795659  0.881051   \n",
       "FedProx μ = 2 LR            0.404814       0.426119       0.449810  0.690481   \n",
       "FedProx μ = 2 MLP           0.810961       0.796162       0.782814  0.758507   \n",
       "\n",
       "                     ...  auc_precision_recall_std  accuracy_score_std  \\\n",
       "algorithm_name       ...                                                 \n",
       "FedAvg LR            ...                  0.030054            0.203317   \n",
       "FedAvg MLP           ...                  0.064040            0.068286   \n",
       "FedAvg SGD           ...                  0.049232            0.046347   \n",
       "FedAvg XGBRF         ...                  0.033034            0.033173   \n",
       "FedProx μ = 0.5 LR   ...                  0.049276            0.263720   \n",
       "FedProx μ = 0.5 MLP  ...                  0.065543            0.062510   \n",
       "FedProx μ = 2 LR     ...                  0.032972            0.262370   \n",
       "FedProx μ = 2 MLP    ...                  0.067098            0.069853   \n",
       "\n",
       "                     precision_score_std  recall_score_std  \\\n",
       "algorithm_name                                               \n",
       "FedAvg LR                       0.324156          0.382898   \n",
       "FedAvg MLP                      0.050626          0.049929   \n",
       "FedAvg SGD                      0.065495          0.048313   \n",
       "FedAvg XGBRF                    0.048316          0.053940   \n",
       "FedProx μ = 0.5 LR              0.409569          0.495139   \n",
       "FedProx μ = 0.5 MLP             0.049365          0.063250   \n",
       "FedProx μ = 2 LR                0.429278          0.511903   \n",
       "FedProx μ = 2 MLP               0.047807          0.075059   \n",
       "\n",
       "                     average_precision_score_std  fbeta_score_0.5_std  \\\n",
       "algorithm_name                                                          \n",
       "FedAvg LR                               0.072955             0.334020   \n",
       "FedAvg MLP                              0.062655             0.048739   \n",
       "FedAvg SGD                              0.048111             0.045812   \n",
       "FedAvg XGBRF                            0.043312             0.032505   \n",
       "FedProx μ = 0.5 LR                      0.096837             0.424166   \n",
       "FedProx μ = 0.5 MLP                     0.063901             0.044433   \n",
       "FedProx μ = 2 LR                        0.097544             0.443571   \n",
       "FedProx μ = 2 MLP                       0.065736             0.046528   \n",
       "\n",
       "                     fbeta_score_1_std  fbeta_score_2_std  log_loss_std  \\\n",
       "algorithm_name                                                            \n",
       "FedAvg LR                     0.350372           0.368974      0.130071   \n",
       "FedAvg MLP                    0.047565           0.048376      0.228905   \n",
       "FedAvg SGD                    0.036258           0.042201      0.071575   \n",
       "FedAvg XGBRF                  0.022274           0.038089      0.000156   \n",
       "FedProx μ = 0.5 LR            0.448186           0.475187      0.147971   \n",
       "FedProx μ = 0.5 MLP           0.046271           0.055405      0.298565   \n",
       "FedProx μ = 2 LR              0.466914           0.492891      0.140463   \n",
       "FedProx μ = 2 MLP             0.052884           0.065264      0.248833   \n",
       "\n",
       "                     matthews_corrcoef_std  \n",
       "algorithm_name                              \n",
       "FedAvg LR                         0.177841  \n",
       "FedAvg MLP                        0.172388  \n",
       "FedAvg SGD                        0.122341  \n",
       "FedAvg XGBRF                      0.109365  \n",
       "FedProx μ = 0.5 LR                0.241376  \n",
       "FedProx μ = 0.5 MLP               0.150623  \n",
       "FedProx μ = 2 LR                  0.203402  \n",
       "FedProx μ = 2 MLP                 0.163476  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "roc_auc_score                  float64\n",
       "auc_precision_recall           float64\n",
       "accuracy_score                 float64\n",
       "precision_score                float64\n",
       "recall_score                   float64\n",
       "average_precision_score        float64\n",
       "fbeta_score_0.5                float64\n",
       "fbeta_score_1                  float64\n",
       "fbeta_score_2                  float64\n",
       "log_loss                       float64\n",
       "matthews_corrcoef              float64\n",
       "roc_auc_score_std              float64\n",
       "auc_precision_recall_std       float64\n",
       "accuracy_score_std             float64\n",
       "precision_score_std            float64\n",
       "recall_score_std               float64\n",
       "average_precision_score_std    float64\n",
       "fbeta_score_0.5_std            float64\n",
       "fbeta_score_1_std              float64\n",
       "fbeta_score_2_std              float64\n",
       "log_loss_std                   float64\n",
       "matthews_corrcoef_std          float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True uniform\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>auc_precision_recall</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>average_precision_score</th>\n",
       "      <th>fbeta_score_0.5</th>\n",
       "      <th>fbeta_score_1</th>\n",
       "      <th>fbeta_score_2</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>...</th>\n",
       "      <th>auc_precision_recall_std</th>\n",
       "      <th>accuracy_score_std</th>\n",
       "      <th>precision_score_std</th>\n",
       "      <th>recall_score_std</th>\n",
       "      <th>average_precision_score_std</th>\n",
       "      <th>fbeta_score_0.5_std</th>\n",
       "      <th>fbeta_score_1_std</th>\n",
       "      <th>fbeta_score_2_std</th>\n",
       "      <th>log_loss_std</th>\n",
       "      <th>matthews_corrcoef_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FedAvg LR</th>\n",
       "      <td>0.689773</td>\n",
       "      <td>0.873723</td>\n",
       "      <td>0.617201</td>\n",
       "      <td>0.533132</td>\n",
       "      <td>0.622066</td>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.548666</td>\n",
       "      <td>0.573892</td>\n",
       "      <td>0.601774</td>\n",
       "      <td>0.655033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041590</td>\n",
       "      <td>0.261588</td>\n",
       "      <td>0.414227</td>\n",
       "      <td>0.482046</td>\n",
       "      <td>0.094197</td>\n",
       "      <td>0.425912</td>\n",
       "      <td>0.445021</td>\n",
       "      <td>0.466358</td>\n",
       "      <td>0.139675</td>\n",
       "      <td>0.249825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedAvg MLP</th>\n",
       "      <td>0.760004</td>\n",
       "      <td>0.872462</td>\n",
       "      <td>0.712220</td>\n",
       "      <td>0.816843</td>\n",
       "      <td>0.767606</td>\n",
       "      <td>0.875032</td>\n",
       "      <td>0.805714</td>\n",
       "      <td>0.790299</td>\n",
       "      <td>0.776266</td>\n",
       "      <td>0.766864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071682</td>\n",
       "      <td>0.083873</td>\n",
       "      <td>0.051478</td>\n",
       "      <td>0.088520</td>\n",
       "      <td>0.068716</td>\n",
       "      <td>0.055323</td>\n",
       "      <td>0.065779</td>\n",
       "      <td>0.079040</td>\n",
       "      <td>0.308273</td>\n",
       "      <td>0.179210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedAvg SGD</th>\n",
       "      <td>0.828008</td>\n",
       "      <td>0.919800</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.904037</td>\n",
       "      <td>0.706573</td>\n",
       "      <td>0.920614</td>\n",
       "      <td>0.855269</td>\n",
       "      <td>0.792077</td>\n",
       "      <td>0.738273</td>\n",
       "      <td>0.544735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024925</td>\n",
       "      <td>0.029390</td>\n",
       "      <td>0.048977</td>\n",
       "      <td>0.032628</td>\n",
       "      <td>0.024662</td>\n",
       "      <td>0.032386</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>0.026878</td>\n",
       "      <td>0.032096</td>\n",
       "      <td>0.083677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedAvg XGBRF</th>\n",
       "      <td>0.828651</td>\n",
       "      <td>0.924113</td>\n",
       "      <td>0.800505</td>\n",
       "      <td>0.847752</td>\n",
       "      <td>0.882629</td>\n",
       "      <td>0.908964</td>\n",
       "      <td>0.853651</td>\n",
       "      <td>0.863494</td>\n",
       "      <td>0.874556</td>\n",
       "      <td>0.690791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014610</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.042688</td>\n",
       "      <td>0.036366</td>\n",
       "      <td>0.018673</td>\n",
       "      <td>0.028679</td>\n",
       "      <td>0.013386</td>\n",
       "      <td>0.023111</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.088943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedProx μ = 0.5 LR</th>\n",
       "      <td>0.754560</td>\n",
       "      <td>0.887329</td>\n",
       "      <td>0.704595</td>\n",
       "      <td>0.671177</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.865850</td>\n",
       "      <td>0.689521</td>\n",
       "      <td>0.719071</td>\n",
       "      <td>0.751377</td>\n",
       "      <td>0.608721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041480</td>\n",
       "      <td>0.208265</td>\n",
       "      <td>0.329532</td>\n",
       "      <td>0.379707</td>\n",
       "      <td>0.081846</td>\n",
       "      <td>0.338324</td>\n",
       "      <td>0.352573</td>\n",
       "      <td>0.368288</td>\n",
       "      <td>0.154714</td>\n",
       "      <td>0.198308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedProx μ = 0.5 MLP</th>\n",
       "      <td>0.756737</td>\n",
       "      <td>0.871983</td>\n",
       "      <td>0.743712</td>\n",
       "      <td>0.829433</td>\n",
       "      <td>0.807512</td>\n",
       "      <td>0.874010</td>\n",
       "      <td>0.824246</td>\n",
       "      <td>0.817234</td>\n",
       "      <td>0.811113</td>\n",
       "      <td>0.976233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060561</td>\n",
       "      <td>0.074669</td>\n",
       "      <td>0.047859</td>\n",
       "      <td>0.075410</td>\n",
       "      <td>0.059007</td>\n",
       "      <td>0.048029</td>\n",
       "      <td>0.054443</td>\n",
       "      <td>0.066003</td>\n",
       "      <td>0.313834</td>\n",
       "      <td>0.181533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedProx μ = 2 LR</th>\n",
       "      <td>0.812445</td>\n",
       "      <td>0.906127</td>\n",
       "      <td>0.777332</td>\n",
       "      <td>0.790153</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.907568</td>\n",
       "      <td>0.815612</td>\n",
       "      <td>0.857081</td>\n",
       "      <td>0.903068</td>\n",
       "      <td>0.581825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040410</td>\n",
       "      <td>0.023524</td>\n",
       "      <td>0.014448</td>\n",
       "      <td>0.024798</td>\n",
       "      <td>0.039429</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.016530</td>\n",
       "      <td>0.020675</td>\n",
       "      <td>0.137376</td>\n",
       "      <td>0.068946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FedProx μ = 2 MLP</th>\n",
       "      <td>0.764644</td>\n",
       "      <td>0.868148</td>\n",
       "      <td>0.738562</td>\n",
       "      <td>0.830074</td>\n",
       "      <td>0.798122</td>\n",
       "      <td>0.871126</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.813290</td>\n",
       "      <td>0.804009</td>\n",
       "      <td>0.900067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060271</td>\n",
       "      <td>0.053685</td>\n",
       "      <td>0.042344</td>\n",
       "      <td>0.045129</td>\n",
       "      <td>0.057369</td>\n",
       "      <td>0.038986</td>\n",
       "      <td>0.037932</td>\n",
       "      <td>0.041217</td>\n",
       "      <td>0.367971</td>\n",
       "      <td>0.133159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     roc_auc_score  auc_precision_recall  accuracy_score  \\\n",
       "algorithm_name                                                             \n",
       "FedAvg LR                 0.689773              0.873723        0.617201   \n",
       "FedAvg MLP                0.760004              0.872462        0.712220   \n",
       "FedAvg SGD                0.828008              0.919800        0.735294   \n",
       "FedAvg XGBRF              0.828651              0.924113        0.800505   \n",
       "FedProx μ = 0.5 LR        0.754560              0.887329        0.704595   \n",
       "FedProx μ = 0.5 MLP       0.756737              0.871983        0.743712   \n",
       "FedProx μ = 2 LR          0.812445              0.906127        0.777332   \n",
       "FedProx μ = 2 MLP         0.764644              0.868148        0.738562   \n",
       "\n",
       "                     precision_score  recall_score  average_precision_score  \\\n",
       "algorithm_name                                                                \n",
       "FedAvg LR                   0.533132      0.622066                 0.828066   \n",
       "FedAvg MLP                  0.816843      0.767606                 0.875032   \n",
       "FedAvg SGD                  0.904037      0.706573                 0.920614   \n",
       "FedAvg XGBRF                0.847752      0.882629                 0.908964   \n",
       "FedProx μ = 0.5 LR          0.671177      0.774648                 0.865850   \n",
       "FedProx μ = 0.5 MLP         0.829433      0.807512                 0.874010   \n",
       "FedProx μ = 2 LR            0.790153      0.936620                 0.907568   \n",
       "FedProx μ = 2 MLP           0.830074      0.798122                 0.871126   \n",
       "\n",
       "                     fbeta_score_0.5  fbeta_score_1  fbeta_score_2  log_loss  \\\n",
       "algorithm_name                                                                 \n",
       "FedAvg LR                   0.548666       0.573892       0.601774  0.655033   \n",
       "FedAvg MLP                  0.805714       0.790299       0.776266  0.766864   \n",
       "FedAvg SGD                  0.855269       0.792077       0.738273  0.544735   \n",
       "FedAvg XGBRF                0.853651       0.863494       0.874556  0.690791   \n",
       "FedProx μ = 0.5 LR          0.689521       0.719071       0.751377  0.608721   \n",
       "FedProx μ = 0.5 MLP         0.824246       0.817234       0.811113  0.976233   \n",
       "FedProx μ = 2 LR            0.815612       0.857081       0.903068  0.581825   \n",
       "FedProx μ = 2 MLP           0.823151       0.813290       0.804009  0.900067   \n",
       "\n",
       "                     ...  auc_precision_recall_std  accuracy_score_std  \\\n",
       "algorithm_name       ...                                                 \n",
       "FedAvg LR            ...                  0.041590            0.261588   \n",
       "FedAvg MLP           ...                  0.071682            0.083873   \n",
       "FedAvg SGD           ...                  0.024925            0.029390   \n",
       "FedAvg XGBRF         ...                  0.014610            0.024691   \n",
       "FedProx μ = 0.5 LR   ...                  0.041480            0.208265   \n",
       "FedProx μ = 0.5 MLP  ...                  0.060561            0.074669   \n",
       "FedProx μ = 2 LR     ...                  0.040410            0.023524   \n",
       "FedProx μ = 2 MLP    ...                  0.060271            0.053685   \n",
       "\n",
       "                     precision_score_std  recall_score_std  \\\n",
       "algorithm_name                                               \n",
       "FedAvg LR                       0.414227          0.482046   \n",
       "FedAvg MLP                      0.051478          0.088520   \n",
       "FedAvg SGD                      0.048977          0.032628   \n",
       "FedAvg XGBRF                    0.042688          0.036366   \n",
       "FedProx μ = 0.5 LR              0.329532          0.379707   \n",
       "FedProx μ = 0.5 MLP             0.047859          0.075410   \n",
       "FedProx μ = 2 LR                0.014448          0.024798   \n",
       "FedProx μ = 2 MLP               0.042344          0.045129   \n",
       "\n",
       "                     average_precision_score_std  fbeta_score_0.5_std  \\\n",
       "algorithm_name                                                          \n",
       "FedAvg LR                               0.094197             0.425912   \n",
       "FedAvg MLP                              0.068716             0.055323   \n",
       "FedAvg SGD                              0.024662             0.032386   \n",
       "FedAvg XGBRF                            0.018673             0.028679   \n",
       "FedProx μ = 0.5 LR                      0.081846             0.338324   \n",
       "FedProx μ = 0.5 MLP                     0.059007             0.048029   \n",
       "FedProx μ = 2 LR                        0.039429             0.014663   \n",
       "FedProx μ = 2 MLP                       0.057369             0.038986   \n",
       "\n",
       "                     fbeta_score_1_std  fbeta_score_2_std  log_loss_std  \\\n",
       "algorithm_name                                                            \n",
       "FedAvg LR                     0.445021           0.466358      0.139675   \n",
       "FedAvg MLP                    0.065779           0.079040      0.308273   \n",
       "FedAvg SGD                    0.021951           0.026878      0.032096   \n",
       "FedAvg XGBRF                  0.013386           0.023111      0.000147   \n",
       "FedProx μ = 0.5 LR            0.352573           0.368288      0.154714   \n",
       "FedProx μ = 0.5 MLP           0.054443           0.066003      0.313834   \n",
       "FedProx μ = 2 LR              0.016530           0.020675      0.137376   \n",
       "FedProx μ = 2 MLP             0.037932           0.041217      0.367971   \n",
       "\n",
       "                     matthews_corrcoef_std  \n",
       "algorithm_name                              \n",
       "FedAvg LR                         0.249825  \n",
       "FedAvg MLP                        0.179210  \n",
       "FedAvg SGD                        0.083677  \n",
       "FedAvg XGBRF                      0.088943  \n",
       "FedProx μ = 0.5 LR                0.198308  \n",
       "FedProx μ = 0.5 MLP               0.181533  \n",
       "FedProx μ = 2 LR                  0.068946  \n",
       "FedProx μ = 2 MLP                 0.133159  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "roc_auc_score                  float64\n",
       "auc_precision_recall           float64\n",
       "accuracy_score                 float64\n",
       "precision_score                float64\n",
       "recall_score                   float64\n",
       "average_precision_score        float64\n",
       "fbeta_score_0.5                float64\n",
       "fbeta_score_1                  float64\n",
       "fbeta_score_2                  float64\n",
       "log_loss                       float64\n",
       "matthews_corrcoef              float64\n",
       "roc_auc_score_std              float64\n",
       "auc_precision_recall_std       float64\n",
       "accuracy_score_std             float64\n",
       "precision_score_std            float64\n",
       "recall_score_std               float64\n",
       "average_precision_score_std    float64\n",
       "fbeta_score_0.5_std            float64\n",
       "fbeta_score_1_std              float64\n",
       "fbeta_score_2_std              float64\n",
       "log_loss_std                   float64\n",
       "matthews_corrcoef_std          float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table_configs = {}\n",
    "table_subset = tables[tables['num_clients'] == NC]\n",
    "for (stratified, split_method), df in table_subset.drop(columns=['val_name', 'fold_idx', 'val_name_std', 'fold_idx_std', 'num_clients', 'num_clients_std']).groupby(['stratified', 'split_method']):\n",
    "    print(stratified, split_method)\n",
    "    df = df.set_index(['algorithm_name']).drop(columns=['algorithm_name_std', 'stratified', 'split_method', 'split_method_std'])\n",
    "    display(df)\n",
    "    table_configs[(stratified, split_method)] = df\n",
    "    display(df.dtypes)\n",
    "\n",
    "uniform_stratified = table_configs[(True, 'uniform')]\n",
    "uniform_random = table_configs[(False, 'uniform')]\n",
    "linear_random = table_configs[(False, 'linear')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_heterogeneity = uniform_stratified - uniform_random\n",
    "# label_size_heterogeneity = uniform_stratified - linear_random\n",
    "\n",
    "# display(label_heterogeneity)\n",
    "# display(label_size_heterogeneity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_precision_recall\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\n",
    "    'gray',\n",
    "    'salmon',\n",
    "    'red',\n",
    "]\n",
    "\n",
    "\n",
    "# plot the delta table\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "bar_width = 0.35\n",
    "group_centers = []\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "f.set_figheight(4)\n",
    "f.set_figwidth(10)\n",
    "\n",
    "print(metric)\n",
    "\n",
    "t = tables[tables['num_clients'] == 2]\n",
    "std_ = f\"{metric}_std\"\n",
    "\n",
    "loc = 0\n",
    "\n",
    "label = True\n",
    "algorithm_names = ['FedAvg LR', 'FedProx μ = 0.5 LR', 'FedProx μ = 2 LR', 'FedAvg MLP', 'FedProx μ = 0.5 MLP', 'FedProx μ = 2 MLP', 'FedAvg SGD', 'FedAvg XGBRF']\n",
    "for alg_name in algorithm_names:\n",
    "    \n",
    "    if label:\n",
    "        label = False\n",
    "        loc += 0.5\n",
    "        score = uniform_stratified.loc[alg_name][metric]\n",
    "        error = np.abs(uniform_stratified.loc[alg_name][std_])\n",
    "        ax.bar(loc, score, bar_width, label='Uniform Stratified', color=colors[0], yerr=error, align='edge')\n",
    "\n",
    "        loc += 0.5\n",
    "        group_centers.append(loc)\n",
    "        score = uniform_random.loc[alg_name][metric]\n",
    "        error = uniform_random.loc[alg_name][std_]\n",
    "        ax.bar(loc, score, bar_width, label='Uniform Random', color=colors[1], yerr=error, align='edge')\n",
    "\n",
    "        loc += 0.5\n",
    "        score = linear_random.loc[alg_name][metric]\n",
    "        error = linear_random.loc[alg_name][std_]\n",
    "        ax.bar(loc, score, bar_width, label='Linear Random', color=colors[2], yerr=error, align='edge')\n",
    "    else:\n",
    "        loc += 0.5\n",
    "        score = uniform_stratified.loc[alg_name][metric]\n",
    "        error = np.abs(uniform_stratified.loc[alg_name][std_])\n",
    "        ax.bar(loc, score, bar_width, color=colors[0], yerr=error, align='edge')\n",
    "\n",
    "        loc += 0.5\n",
    "        group_centers.append(loc + 0.25)\n",
    "        score = uniform_random.loc[alg_name][metric]\n",
    "        error = uniform_random.loc[alg_name][std_]\n",
    "        ax.bar(loc, score, bar_width, color=colors[1], yerr=error, align='edge')\n",
    "\n",
    "        loc += 0.5\n",
    "        score = linear_random.loc[alg_name][metric]\n",
    "        error = linear_random.loc[alg_name][std_]\n",
    "        ax.bar(loc, score, bar_width, color=colors[2], yerr=error, align='edge')\n",
    "\n",
    "    loc += 0.5\n",
    "\n",
    "ax.set_xticks(group_centers)\n",
    "ax.set_xticklabels(algorithm_names, fontsize=10, rotation=20, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "ax.set_xlabel('FL Algorithm')\n",
    "ax.set_ylabel('AUC-PR')\n",
    "\n",
    "ax.grid(axis='y')\n",
    "ax.set_ylim(0.75, 1)\n",
    "# ax.set_ylim(0.7, 0.95)\n",
    "ax.legend(loc='lower right', framealpha=1)\n",
    "\n",
    "ax.set_title(f'Algorithm Performance as Hetergeniety Increase (N={NC}, {dataset})')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(tables_path, f'hetrogeniety_visualization_among_clients_n={NC}_{dataset}.png'), dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nih_fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
